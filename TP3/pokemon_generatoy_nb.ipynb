{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.metrics import binary_crossentropy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2  # pip3 install opencv-python\n",
    "\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()\n",
    "\n",
    "# IMAGES_PATH = \"data/GS_pokemon_images/\"\n",
    "IMAGES_PATH = \"data/pokemon_images/\"\n",
    "# NUM_CHANNELS = 1\n",
    "NUM_CHANNELS = 3  # RGB\n",
    "IMAGE_SIZE = 96\n",
    "INPUT_DIM = IMAGE_SIZE * IMAGE_SIZE * NUM_CHANNELS\n",
    "FIRST_INTERMEDIATE_DIM = 1024\n",
    "SECOND_INTERMEDIATE_DIM = 256\n",
    "LATENT_DIM = 2  # tiene que ser 2 para poder ser graficado en un plot\n",
    "EPOCHS = 500\n",
    "\n",
    "def sampling(args: tuple):\n",
    "    z_mean, z_log_var = args\n",
    "    print(z_mean)\n",
    "    print(z_log_var)\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], LATENT_DIM), mean=0., stddev=1.)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon  # h(z)\n",
    "\n",
    "\n",
    "def read_pokemon_images():\n",
    "    X = []\n",
    "    y = []\n",
    "    for image_file_name in os.listdir(IMAGES_PATH):\n",
    "        image = keras.preprocessing.image.load_img(IMAGES_PATH + image_file_name, target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "        image = keras.preprocessing.image.img_to_array(image)\n",
    "        image = image / 255.0\n",
    "        X.append(image)\n",
    "        # get id in file name\n",
    "        image_id = image_file_name.split(\".\")[0].split(\"/\")[-1]\n",
    "        y.append(int(image_id))\n",
    "\n",
    "    X = np.array(X)\n",
    "    # reshape so its a 4d array\n",
    "    X = X.reshape(-1, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)\n",
    "    X = X.reshape((len(X), np.prod(X.shape[1:])))\n",
    "\n",
    "    # example of image\n",
    "    # plt.figure(figsize=(10, 10))\n",
    "    # plt.imshow(images[0][:, :, 0])\n",
    "    # plt.show()\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load input\n",
    "X, y = read_pokemon_images()\n",
    "X_train = X_test = X\n",
    "y_train = y_test = y\n",
    "\n",
    "# --------------------------- encoder ---------------------------\n",
    "x = Input(shape=(INPUT_DIM,), name=\"input\")\n",
    "# intermediate layer\n",
    "h = Dense(FIRST_INTERMEDIATE_DIM, activation='relu', name=\"encoding\")(x)\n",
    "h = Dense(SECOND_INTERMEDIATE_DIM, activation='relu', name=\"encoding2\")(x)\n",
    "# defining the mean of the latent space\n",
    "z_mean = Dense(LATENT_DIM, name=\"mean\")(h)\n",
    "# defining the log variance of the latent space\n",
    "z_log_var = Dense(LATENT_DIM, name=\"log-variance\")(h)\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(LATENT_DIM,))([z_mean, z_log_var])\n",
    "# defining the encoder as a keras model\n",
    "encoder = Model(x, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "# print out summary of what we just did\n",
    "encoder.summary()\n",
    "\n",
    "# --------------------------- decoder ---------------------------\n",
    "input_decoder = Input(shape=(LATENT_DIM,), name=\"decoder_input\")\n",
    "# taking the latent space to intermediate dimension\n",
    "decoder_h = Dense(SECOND_INTERMEDIATE_DIM, activation='relu', name=\"decoder_h2\")(input_decoder)\n",
    "decoder_h = Dense(FIRST_INTERMEDIATE_DIM, activation='relu', name=\"decoder_h\")(input_decoder)\n",
    "# getting the mean from the original dimension\n",
    "x_decoded = Dense(INPUT_DIM, activation='sigmoid', name=\"flat_decoded\")(decoder_h)\n",
    "# defining the decoder as a keras model\n",
    "decoder = Model(input_decoder, x_decoded, name=\"decoder\")\n",
    "decoder.summary()\n",
    "\n",
    "# --------------------------- VAE ---------------------------\n",
    "# grab the output. Recall, that we need to grab the 3rd element our sampling z\n",
    "output_combined = decoder(encoder(x)[2])\n",
    "# link the input and the overall output\n",
    "vae = Model(x, output_combined)\n",
    "# print out what the overall model looks like\n",
    "vae.summary()\n",
    "\n",
    "\n",
    "def vae_loss(x: tf.Tensor, x_decoded_mean: tf.Tensor):\n",
    "    # Aca se computa la cross entropy entre los \"labels\" x que son los valores 0/1 de los pixeles, y lo que sali√≥ al final del Decoder.\n",
    "    xent_loss = INPUT_DIM * binary_crossentropy(x, x_decoded_mean)  # x-^X\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    vae_loss = K.mean(xent_loss + kl_loss)\n",
    "    return vae_loss\n",
    "\n",
    "\n",
    "vae.compile(loss=vae_loss, optimizer='rmsprop')\n",
    "vae.summary()\n",
    "\n",
    "history = vae.fit(X_train, X_train, epochs=EPOCHS, batch_size=20, shuffle=True)\n",
    "#plot error vs epoch\n",
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.show()\n",
    "\n",
    "# Para ver el rango de latent space?\n",
    "x_test_encoded = encoder.predict(X_test)[0]\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.show(block=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_vector = np.array([[-6,14]])\n",
    "decoded_example = decoder.predict(sample_vector)\n",
    "decoded_example_reshaped = decoded_example.reshape(IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)\n",
    "plt.imshow(decoded_example_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "n=15\n",
    "# generate nxn samples\n",
    "figure = np.zeros((IMAGE_SIZE * n, IMAGE_SIZE * n, 3))\n",
    "\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "print(grid_x)\n",
    "# grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_x = np.linspace(-13, 30, n)\n",
    "grid_y = np.linspace(-15, 20, n)\n",
    "print(grid_x)\n",
    "\n",
    "# decoder for each square in the grid\n",
    "for i, yi in enumerate(grid_y):\n",
    "    for j, xi in enumerate(grid_x):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = decoder.predict(z_sample)[0]\n",
    "        image = x_decoded.reshape(IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "        figure[i * IMAGE_SIZE: (i + 1) * IMAGE_SIZE,\n",
    "        j * IMAGE_SIZE: (j + 1) * IMAGE_SIZE] = image\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "fig_shape = np.shape(figure)\n",
    "figure = figure.reshape((fig_shape[0], fig_shape[1], fig_shape[2]))\n",
    "\n",
    "plt.imshow(figure)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('TP3-y8jPdXia')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3dfd9a75f1a40cb353d05ad7dded7e12ff0ce79d3ad7420eb9f458bcdd9bb673"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
